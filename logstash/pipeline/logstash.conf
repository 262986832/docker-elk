input {
    kafka {
        bootstrap_servers => "10.10.X.A:9092,10.10.X.B:9092,10.10.X.C:9092"
        consumer_threads => 6 ## 设置成 partition 数量即可
        decorate_events => false
        topics => ["log-im"]
        group_id => "group-log-im"
        type => "log-im"
    }
}

## Add your filters / logstash plugins configuration here
filter {
    mutate {
        remove_field => [ "@version" ]
    }
    json {
        source => "message"
        skip_on_invalid_json => true
        remove_field => [ "message" ]
    }
    date {
        match => [ "time", "ISO8601", "EEE MMM dd yyyy HH:mm:ss 'GMT'Z '(CST)'", "dd/MMM/yyyy:HH:mm:ss Z", "yy-MM-dd HH:mm:ss", "dd-MMM-yyyy HH:mm:ss ZZZ", "yyyy-MM-dd HH:mm:ss ZZ", "yyyy-MM-dd HH:mm ZZ" ]
        remove_field => [ "time" ]
    }
}

output {
    ## 按 type 区分不同 topic 的日志，然后写入不同的目录
    if [type] == "log-im" {
        elasticsearch {
            hosts => ["localhost:9200", "10.42.X.B:9200", "10.42.X.C:9200"]
            index => "%{type}-%{+YYYY.MM.dd}"
        }
    }
}
